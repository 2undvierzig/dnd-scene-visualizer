#!/usr/bin/env python3
"""
D&D Bildgenerator - Erstellt Bildgenerierungs-Prompts basierend auf D&D-Session-Transkripten.
"""
import ollama
import parse_transkript
import img_gen
import re
import sys
import logging
import pathlib
import json
import socket
from datetime import datetime

def get_required_model():
    """L√§dt das erforderliche Modell aus der Konfiguration."""
    try:
        with open('run_config.json', 'r') as f:
            config = json.load(f)
        return config['services']['ollama']['required_model']
    except Exception:
        return "deepseek-r1:14b"  # Fallback

def create_system_prompt():
    """Erstellt den System-Prompt f√ºr das LLM."""
    return """You are an expert Dungeons & Dragons scene analyst and image prompt generator specialized for the "dndstyle" LoRA model.

Your task is to:
1. Analyze the provided D&D session transcript excerpt
2. Identify the current situation, location, characters, and atmosphere
3. Generate a detailed image generation prompt optimized for the "dndstyle" model

CRITICAL OUTPUT FORMAT:
You MUST format your response EXACTLY as follows (after any thinking):

SCENE ANALYSIS: [Brief description of what's happening]

DNDSTYLE IMAGE PROMPT: dndstyle, [your detailed prompt here]

IMAGE NAME: [descriptive filename without extension, use underscores instead of spaces]

IMAGE PROMPT REQUIREMENTS:
- MUST start with "dndstyle" as the trigger word
- Be optimized for a LoRA model trained on D&D illustrations
- Capture key visual elements (characters, environment, objects, lighting)
- Focus on the most dramatic or visually interesting moment
- Include specific D&D fantasy elements (races, classes, equipment, creatures)
- Include atmospheric details (mood, lighting, weather, dungeon ambiance)
- Be concise but descriptive (avoid overly long prompts)
- Use D&D-specific terminology and visual style descriptions

IMAGE NAME REQUIREMENTS:
- ONLY use ASCII letters (a-z, A-Z), numbers (0-9), and underscores (_)
- NO special characters, spaces, accents, or non-English characters
- Maximum 50 characters long
- Use descriptive English words separated by underscores
- Examples: "party_discovers_artifact", "dragon_combat_dungeon", "ancient_chamber_frescoes"

EXAMPLE OUTPUT:
SCENE ANALYSIS: The party discovers a hidden chamber with ancient frescoes depicting dragons and knights. A mysterious artifact glows brighter as it's placed on an ornate altar.

DNDSTYLE IMAGE PROMPT: dndstyle, fantasy adventurers in ancient stone chamber, ornate altar with glowing artifact, dragon and knight frescoes on walls, torchlight atmosphere, dramatic lighting, D&D illustration style

IMAGE NAME: party_discovers_artifact_chamber

Remember: The output format is CRITICAL. Always include all three sections exactly as shown. The IMAGE NAME must be valid ASCII-only filename."""

def setup_logging():
    """Konfiguriert Logging f√ºr Debug-Ausgaben mit besserer Sichtbarkeit."""
    # Console Handler mit einfachem Format (ohne Farben f√ºr Kompatibilit√§t)
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter(
        '\033[94m[DnD-IMG]\033[0m %(asctime)s - %(levelname)s - %(message)s'
    )
    console_handler.setFormatter(console_formatter)
    
    # File Handler mit detaillierten Infos
    file_handler = logging.FileHandler('dnd_image_generator.log', encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'
    )
    file_handler.setFormatter(file_formatter)
    
    # Logger konfigurieren
    logger = logging.getLogger('DnDImageGenerator')
    logger.setLevel(logging.DEBUG)
    logger.addHandler(console_handler)
    logger.addHandler(file_handler)
    
    return logger

def check_service_availability():
    """Pr√ºft die Verf√ºgbarkeit aller ben√∂tigten Services."""
    logger = logging.getLogger('DnDImageGenerator')
    
    # Ollama Service pr√ºfen
    try:
        logger.info("üîç Pr√ºfe Ollama Service...")
        response = ollama.list()
        models = [model['name'] for model in response.get('models', [])]
        logger.info(f"Verf√ºgbare Modelle: {models}")
        
        required_model = get_required_model()
        logger.debug(f"Erforderliches Modell gefunden: {required_model}")
        
        if required_model in models:
            logger.info(f"‚úÖ {required_model} Modell verf√ºgbar")
        else:
            logger.warning(f"‚ö†Ô∏è {required_model} Modell nicht gefunden")
            return False
    except Exception as e:
        logger.error(f"‚ùå Ollama Service nicht verf√ºgbar: {e}")
        return False
    
    # Image Generation Service pr√ºfen
    try:
        logger.info("üîç Pr√ºfe Image Generation Service...")
        config_path = pathlib.Path("img_gen_service.json")
        
        if not config_path.exists():
            logger.error("‚ùå img_gen_service.json nicht gefunden")
            return False
        
        with open(config_path, 'r') as f:
            config = json.load(f)
        
        host = config.get('host', 'localhost')
        port = config.get('port', 5555)
        
        # Socket-Test
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(5)
        result = sock.connect_ex((host, port))
        sock.close()
        
        if result == 0:
            logger.info(f"‚úÖ Image Service erreichbar auf {host}:{port}")
            return True
        else:
            logger.error(f"‚ùå Image Service nicht erreichbar auf {host}:{port}")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Fehler beim Pr√ºfen des Image Service: {e}")
        return False

def analyze_transcript_and_generate_prompt(transcript_text):
    """
    Analysiert das Transkript und generiert einen Bildgenerierungs-Prompt.
    
    Args:
        transcript_text (list): Liste der Transkript-Zeilen
        
    Returns:
        str: Der generierte Bildgenerierungs-Prompt
    """
    logger = logging.getLogger('DnDImageGenerator')
    logger.info("üß† Starte LLM-Analyse...")
    
    # System-Prompt erstellen
    system_prompt = create_system_prompt()
    
    # Transkript-Text vorbereiten
    transcript_content = "\n".join(transcript_text)
    logger.debug(f"Transkript-Inhalt ({len(transcript_text)} Zeilen):\n{transcript_content[:200]}...")
    
    # User-Prompt erstellen
    user_prompt = f"""Here is a D&D session transcript excerpt from the last 5 minutes:

{transcript_content}

Please analyze this transcript and generate an appropriate image generation prompt for the current scene."""
    
    # Vollst√§ndigen Prompt zusammenstellen
    full_prompt = f"{system_prompt}\n\n{user_prompt}"
    logger.debug(f"Vollst√§ndiger Prompt-L√§nge: {len(full_prompt)} Zeichen")
    
    # Ollama abfragen mit Retry-Logik
    max_retries = 3
    retry_delay = 5
    
    for attempt in range(max_retries):
        try:
            logger.info(f"ü§ñ Ollama Abfrage (Versuch {attempt + 1}/{max_retries})...")
            start_time = datetime.now()
            
            model_name = get_required_model()
            
            # Verwende richtige Ollama API
            try:
                response = ollama.chat(
                    model=model_name,
                    messages=[{'role': 'user', 'content': full_prompt}],
                    options={
                        'temperature': 0.7,
                        'top_p': 0.9,
                        'num_predict': 1500,
                        'num_ctx': 4096
                    }
                )
            except AttributeError:
                # Fallback f√ºr √§ltere ollama API
                try:
                    response = ollama.generate(
                        model=model_name, 
                        prompt=full_prompt,
                        options={
                            'temperature': 0.7,
                            'top_p': 0.9,
                            'num_predict': 1500,
                            'num_ctx': 4096
                        }
                    )
                except AttributeError:
                    # Letzte Option: Client verwenden
                    client = ollama.Client()
                    response = client.generate(
                        model=model_name, 
                        prompt=full_prompt,
                        options={
                            'temperature': 0.7,
                            'top_p': 0.9,
                            'num_predict': 1500,
                            'num_ctx': 4096
                        }
                    )
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            logger.info(f"ü§ñ LLM-Analyse abgeschlossen nach {duration:.1f}s")
            
            # Extrahiere Antwort je nach API-Format
            response_text = None
            
            if response:
                if 'message' in response and 'content' in response['message']:
                    # Neue chat API
                    response_text = response['message']['content']
                elif 'response' in response:
                    # Alte generate API
                    response_text = response['response']
                
            if response_text:
                logger.info(f"‚úÖ LLM-Antwort erhalten nach {duration:.1f}s")
                logger.debug(f"Antwort-L√§nge: {len(response_text)} Zeichen")
                return response_text
            else:
                logger.warning(f"‚ö†Ô∏è Leere oder ung√ºltige Antwort von Ollama")
                logger.debug(f"Response-Struktur: {response.keys() if response else 'None'}")
                
        except Exception as e:
            logger.error(f"‚ùå Ollama-Abfrage fehlgeschlagen (Versuch {attempt + 1}): {e}")
            if attempt < max_retries - 1:
                logger.info(f"‚è≥ Warte {retry_delay}s vor n√§chstem Versuch...")
                import time
                time.sleep(retry_delay)
            else:
                return f"Fehler bei der Ollama-Abfrage nach {max_retries} Versuchen: {e}"
    
    return "Fehler: Alle Ollama-Abfrage-Versuche fehlgeschlagen"

def parse_llm_response(response_text):
    """
    Parst die LLM-Antwort und extrahiert Prompt und Bildname.
    Unterst√ºtzt DeepSeek-R1 Format mit <think> Tags.
    
    Args:
        response_text (str): Die Antwort vom LLM
        
    Returns:
        tuple: (image_prompt, image_name) oder (None, None) bei Fehlern
    """
    logger = logging.getLogger('DnDImageGenerator')
    logger.info("üîç Parse LLM-Antwort...")
    
    try:
        logger.debug(f"üìù LLM-Antwort (erste 200 Zeichen): {response_text[:200]}")
        
        # F√ºr DeepSeek-R1: Entferne <think> Abschnitte falls vorhanden
        clean_response = response_text
        if '<think>' in response_text and '</think>' in response_text:
            # Extrahiere alles nach dem </think> Tag
            after_think = response_text.split('</think>')
            if len(after_think) > 1:
                clean_response = after_think[1].strip()
                logger.debug(f"üß† <think> Abschnitt entfernt, verarbeite: {clean_response[:100]}...")
        
        # DNDSTYLE IMAGE PROMPT extrahieren (mehrere Pattern probieren)
        prompt_patterns = [
            r'DNDSTYLE IMAGE PROMPT:\s*(.+?)(?=\nIMAGE NAME:|$)',
            r'IMAGE PROMPT:\s*(.+?)(?=\nIMAGE NAME:|$)', 
            r'PROMPT:\s*(.+?)(?=\nIMAGE NAME:|$)',
            r'dndstyle[,\s]+(.+?)(?=\nIMAGE NAME:|$)'
        ]
        
        # IMAGE NAME extrahieren
        name_patterns = [
            r'IMAGE NAME:\s*(.+?)(?=\n|$)',
            r'NAME:\s*(.+?)(?=\n|$)',
            r'FILENAME:\s*(.+?)(?=\n|$)'
        ]
        
        image_prompt = None
        image_name = None
        
        # Prompt Pattern suchen
        for pattern in prompt_patterns:
            match = re.search(pattern, clean_response, re.IGNORECASE | re.DOTALL)
            if match:
                image_prompt = match.group(1).strip()
                # Entferne LLM-Formatierung wie ** am Anfang
                image_prompt = re.sub(r'^\*+\s*', '', image_prompt)
                logger.debug(f"‚úÖ Prompt gefunden mit Pattern: {pattern}")
                break
        
        # Name Pattern suchen 
        for pattern in name_patterns:
            match = re.search(pattern, clean_response, re.IGNORECASE)
            if match:
                image_name = match.group(1).strip()
                logger.debug(f"‚úÖ Name gefunden mit Pattern: {pattern}")
                break
        
        # Fallback: Wenn strukturierte Antwort nicht gefunden wird
        if not image_prompt or not image_name:
            logger.warning("‚ö†Ô∏è Strukturierte Antwort nicht gefunden, verwende Fallback-Parsing...")
            
            # Suche nach "dndstyle" im Text
            dndstyle_match = re.search(r'(dndstyle[^.!?\n]+)', clean_response, re.IGNORECASE)
            if dndstyle_match:
                image_prompt = dndstyle_match.group(1).strip()
                image_name = "generated_scene"
                logger.info(f"üîß Fallback-Prompt extrahiert: {image_prompt}")
            else:
                # Als letzter Ausweg: Erstelle grundlegenden Prompt
                image_prompt = "dndstyle fantasy adventure scene, dungeons and dragons style illustration"
                image_name = "fallback_scene"
                logger.warning(f"üÜò Fallback auf Basis-Prompt: {image_prompt}")
        
        if image_prompt and image_name:
            logger.info(f"‚úÖ Extrahiert - Bildname (roh): '{image_name}'")
            logger.info(f"‚úÖ Extrahiert - Prompt: '{image_prompt[:100]}...'")
            
            # Erweiterte Bildname-Bereinigung
            original_name = image_name
            
            # Entferne LLM-Formatierung wie **, f√ºhrende/trailing Sterne, etc.
            clean_image_name = re.sub(r'^\*+\s*|\s*\*+$', '', image_name)
            
            # Entferne alles in Klammern (wie "(Secret Chamber)")
            clean_image_name = re.sub(r'\s*\([^)]*\)', '', clean_image_name)
            
            # Entferne alle Nicht-ASCII-Zeichen und ersetze sie durch Unterstriche
            clean_image_name = re.sub(r'[^\x00-\x7F]', '_', clean_image_name)
            
            # Erlaube nur alphanumerische Zeichen und Unterstriche
            clean_image_name = re.sub(r'[^a-zA-Z0-9_]', '_', clean_image_name)
            
            # Entferne mehrfache Unterstriche
            clean_image_name = re.sub(r'_{2,}', '_', clean_image_name)
            
            # Entferne f√ºhrende/trailing Unterstriche
            clean_image_name = clean_image_name.strip('_')
            
            # Falls Name leer oder zu kurz, verwende Fallback
            if len(clean_image_name) < 3:
                clean_image_name = "generated_scene"
                logger.warning(f"‚ö†Ô∏è Bildname war unbrauchbar, verwende Fallback: '{clean_image_name}'")
            
            # Begrenze L√§nge auf 35 Zeichen (um Platz f√ºr Timestamp zu lassen)
            if len(clean_image_name) > 35:
                clean_image_name = clean_image_name[:35].rstrip('_')
            
            # F√ºge Minutentimestamp hinzu
            from datetime import datetime
            minute_timestamp = datetime.now().strftime("%H%M")
            timestamped_name = f"{minute_timestamp}_{clean_image_name}"
            
            if timestamped_name != original_name:
                logger.info(f"üßπ Bildname bereinigt: '{original_name}' ‚Üí '{timestamped_name}'")
            
            return image_prompt, timestamped_name
        else:
            logger.error("‚ùå Konnte Prompt oder Bildname nicht aus LLM-Antwort extrahieren")
            logger.debug(f"üêõ Vollst√§ndige LLM-Antwort:\n{response_text}")
            return None, None
            
    except Exception as e:
        logger.error(f"‚ùå Fehler beim Parsen der LLM-Antwort: {e}")
        logger.debug(f"üêõ Vollst√§ndige LLM-Antwort:\n{response_text}")
        return None, None

def generate_image_from_prompt(image_prompt, image_name):
    """
    Generiert ein Bild basierend auf dem Prompt und Bildnamen.
    
    Args:
        image_prompt (str): Der Bildgenerierungs-Prompt
        image_name (str): Der gew√ºnschte Bildname
        
    Returns:
        dict: Ergebnis der Bildgenerierung oder None bei Fehlern
    """
    logger = logging.getLogger('DnDImageGenerator')
    logger.info("üé® Starte Bildgenerierung...")
    
    try:
        # PNG-Extension hinzuf√ºgen
        if not image_name.endswith('.png'):
            image_name += '.png'
        
        logger.info(f"üìÅ Ziel-Datei: {image_name}")
        logger.info(f"üé≠ Prompt: {image_prompt}")
        
        # Pr√ºfe Image Service vor Generierung
        if not check_image_service_connectivity():
            logger.error("‚ùå Image Service nicht verf√ºgbar - √ºberspringe Bildgenerierung")
            return None
        
        start_time = datetime.now()
        logger.info("üöÄ Sende Anfrage an Image Generation Service...")
        
        result = img_gen.generate_img(image_prompt, image_name)
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        if result:
            logger.info(f"‚úÖ Bildgenerierung erfolgreich nach {duration:.1f}s")
            logger.info(f"üìä Ergebnis: {result}")
            return result
        else:
            logger.error(f"‚ùå Bildgenerierung fehlgeschlagen nach {duration:.1f}s")
            return None
        
    except Exception as e:
        logger.error(f"‚ùå Fehler bei der Bildgenerierung: {e}")
        return None

def check_image_service_connectivity():
    """Schnelle Konnektivit√§tspr√ºfung f√ºr Image Service."""
    try:
        config_path = pathlib.Path("img_gen_service.json")
        if not config_path.exists():
            return False
        
        with open(config_path, 'r') as f:
            config = json.load(f)
        
        host = config.get('host', 'localhost')
        port = config.get('port', 5555)
        
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(2)
        result = sock.connect_ex((host, port))
        sock.close()
        
        return result == 0
    except:
        return False

def main():
    """Hauptfunktion des Scripts."""
    # Logging konfigurieren
    logger = setup_logging()
    
    logger.info("üé≤ === D&D Bildgenerator gestartet ===")
    
    try:
        # Service-Verf√ºgbarkeit pr√ºfen
        logger.info("üîß Pr√ºfe Service-Verf√ºgbarkeit...")
        if not check_service_availability():
            logger.error("‚ùå Nicht alle Services verf√ºgbar - Script beendet")
            return False
        
        # Transkript laden
        logger.info("üìñ Lade Transkript...")
        try:
            parser = parse_transkript.TranskriptParser("transcript.txt")
            letzte_5_min = parser.get_transkript(5)
        except Exception as e:
            logger.error(f"‚ùå Fehler beim Laden des Transkripts: {e}")
            return False
        
        if not letzte_5_min:
            logger.warning("‚ö†Ô∏è Keine Transkript-Daten in den letzten 5 Minuten gefunden")
            return False
        
        logger.info(f"‚úÖ Gefunden: {len(letzte_5_min)} Eintr√§ge aus den letzten 5 Minuten")
        
        # Transkript-Inhalt loggen (gek√ºrzt)
        logger.debug("üìÑ Transkript-Inhalt:")
        for i, eintrag in enumerate(letzte_5_min[:3]):  # Nur erste 3 zeigen
            logger.debug(f"  {i+1}: {eintrag}")
        if len(letzte_5_min) > 3:
            logger.debug(f"  ... und {len(letzte_5_min) - 3} weitere Eintr√§ge")
        
        # LLM-Analyse
        logger.info("üß† Starte LLM-Analyse...")
        generated_prompt = analyze_transcript_and_generate_prompt(letzte_5_min)
        
        if generated_prompt.startswith("Fehler"):
            logger.error(f"‚ùå LLM-Analyse fehlgeschlagen: {generated_prompt}")
            return False
        
        logger.info("‚úÖ LLM-Analyse erfolgreich")
        logger.debug(f"üìù Generierte Antwort (erste 200 Zeichen):\n{generated_prompt[:200]}...")
        
        # Parsing
        image_prompt, image_name = parse_llm_response(generated_prompt)
        
        if image_prompt and image_name:
            logger.info("‚úÖ Prompt und Bildname erfolgreich extrahiert")
            
            # Bildgenerierung
            result = generate_image_from_prompt(image_prompt, image_name)
            
            if result:
                logger.info("üéâ Bildgenerierung komplett erfolgreich!")
                logger.info(f"üìÅ Generiertes Bild verf√ºgbar")
                return True
            else:
                logger.error("‚ùå Bildgenerierung fehlgeschlagen")
                return False
        else:
            logger.error("‚ùå Konnte Prompt oder Bildname nicht extrahieren")
            logger.debug(f"üìù Vollst√§ndige LLM-Antwort:\n{generated_prompt}")
            return False
        
    except KeyboardInterrupt:
        logger.info("‚ö†Ô∏è Script durch Benutzer unterbrochen")
        return False
    except Exception as e:
        logger.error(f"‚ùå Unerwarteter Fehler: {e}", exc_info=True)
        return False
    finally:
        logger.info("üîª D&D Bildgenerator beendet")

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
    main() 